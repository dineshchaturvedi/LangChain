{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5c6172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGCHAIN_TRACING_V2: true\n",
      "LANGCHAIN_PROJECT: GenAIAPPWithOPENAI\n"
     ]
    }
   ],
   "source": [
    "### Simple Gen AI App using Langchain\n",
    "### Load the keys from the environment variable in .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Langsmith tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\" \n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "\n",
    "# Add a print statement to confirm its value right before LLM invocation\n",
    "print(f\"LANGCHAIN_TRACING_V2: {os.getenv('LANGCHAIN_TRACING_V2')}\")\n",
    "print(f\"LANGCHAIN_PROJECT: {os.getenv('LANGCHAIN_PROJECT')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e503a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x1812ec86350>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Injestion from the WebSite we need to scrape the data\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Initialize the WebBaseLoder\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/set_up_billing\")\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c04fb1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/administration/how_to_guides/organization_management/set_up_billing', 'title': 'Set up billing for your LangSmith account | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'If you are interested in the Enterprise plan, please contact sales. This guide is', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nSet up billing for your LangSmith account | ü¶úÔ∏èüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationTutorialsOptimize tracing spend on LangSmithHow-to GuidesSetupCreate an account and API keySet up an organizationSet up a workspaceSet up billing for your LangSmith accountUpdate invoice email, tax id and, business informationManage your organization using the APISet up access controlSet up resource tagsSAML SSOConceptual GuideSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceAdministrationHow-to GuidesSetupSet up billing for your LangSmith accountOn this pageSet up billing for your LangSmith account\\nnoteIf you are interested in the Enterprise plan, please contact sales. This guide is\\nonly for our self-serve billing plans.\\nnoteIf you created your LangSmith organization before pricing was introduced on April 2nd, 2024, please skip to the final section.\\nTo set up billing for your LangSmith organization, head to the Usage and Billing page under Settings.\\nDepending on your organization\\'s settings, you will be given a different walkthrough to get started.\\nDeveloper Plan: set up billing on your personal organization\\u200b\\nPersonal organizations are limited to 5000 traces per month until a credit card is added. You can\\nadd a credit card on the Plans and Billing page as follows:\\n1. Click Set up Billing\\u200b\\n\\n2. Add your credit card info\\u200b\\nAfter this step, you will no longer be rate limited to 5000 traces, and will be charged for any excess\\ntraces at rates specified on our pricing page.\\nPlus Plan: set up billing on a shared organization\\u200b\\nIf you have not yet created an organization, please do so by following this guide. This walkthrough assumes you are\\nalready in a new organization.\\nnoteNew organizations are not usable until a credit card is entered. After you complete the following steps, you will\\ngain complete access to LangSmith.\\n1. Click Subscribe on the Plus page\\u200b\\nnoteIf you are a startup building with AI, please instead click Apply Now on our Startup Plan. You may be\\neligible for discounted prices and a generous free, monthly trace allotment.\\n\\n2. Review your existing members\\u200b\\nBefore subscribing, LangSmith lets you remove any added users that you would not\\nlike to be charged for.\\n\\n3. Enter your credit card info\\u200b\\nEnter business information, invoice email and tax id\\u200b\\nIf this organization belongs to a business. Please check the \"This is a business\" checkbox and enter the information accordingly.\\nFor more information refer to this guide\\nOnce this step is complete, your org should now have access to the rest of LangSmith!\\nSet up billing for accounts created before pricing was introduced on April 2, 2024\\u200b\\nIf you joined LangSmith before pricing was introduced April 2, 2024, you have the option to upgrade your\\nexisting account to setup billing. If you did not set up billing by July 8, 2024, then your account is now\\nrate limited to a maximum of 5,000 traces per month.\\n1. Head to the Settings page page under Settings\\u200b\\n2. Click Set up Billing\\u200b\\n\\n3. Enter your credit card info\\u200b\\nIf you are on a Personal Organization, this will add you to the Developer plan. If you are on a shared Organization, this will add you to the Plus plan. For more information,\\nplease view the above walkthroughs for Developer or Plus respectively, starting at step 2.\\n4. Claim free credits as a thank you for being an early LangSmith user\\u200bWas this page helpful?You can leave detailed feedback on GitHub.PreviousSet up a workspaceNextUpdate invoice email, tax id and, business informationDeveloper Plan: set up billing on your personal organization1. Click Set up Billing2. Add your credit card infoPlus Plan: set up billing on a shared organization1. Click Subscribe on the Plus page2. Review your existing members3. Enter your credit card infoSet up billing for accounts created before pricing was introduced on April 2, 20241. Head to the  page under Settings2. Click Set up Billing3. Enter your credit card info4. Claim free credits as a thank you for being an early LangSmith userCommunityTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.\\n\\n')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the documents when calling the load function\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6129b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step2 Divide the contents into chunks\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# This line initializes an instance of the RecursiveCharacterTextSplitter.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "# This line takes the loaded documents (docs) and splits them into smaller, manageable chunks.\n",
    "documents = text_splitter.split_documents(docs)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee4bd6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1814961bbb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 3 convert text chunks into vectors\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# This line initializes an instance of the OpenAIEmbeddings class\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# This is the core step where the text chunks are converted into numerical embeddings and \n",
    "# then stored in a FAISS vector store\n",
    "'''More details on this step is below\n",
    "# When you call FAISS.from_documents(documents, embeddings), the FAISS \n",
    "# library iterates through each Document in the documents list.\n",
    "# For each document's text content, it uses the embeddings object to call the \n",
    "# OpenAI embedding API (or a local embedding model, if configured differently). \n",
    "# This call converts the text into a numerical vector\n",
    "'''\n",
    "vectorstoredb = FAISS.from_documents(documents,embeddings)\n",
    "\n",
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16dfcc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2. Add your credit card info\\u200b\\nAfter this step, you will no longer be rate limited to 5000 traces, and will be charged for any excess\\ntraces at rates specified on our pricing page.\\nPlus Plan: set up billing on a shared organization\\u200b\\nIf you have not yet created an organization, please do so by following this guide. This walkthrough assumes you are\\nalready in a new organization.\\nnoteNew organizations are not usable until a credit card is entered. After you complete the following steps, you will\\ngain complete access to LangSmith.\\n1. Click Subscribe on the Plus page\\u200b\\nnoteIf you are a startup building with AI, please instead click Apply Now on our Startup Plan. You may be\\neligible for discounted prices and a generous free, monthly trace allotment.\\n\\n2. Review your existing members\\u200b\\nBefore subscribing, LangSmith lets you remove any added users that you would not\\nlike to be charged for.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quering the result from the vector store by passing a text from website to see what it does.\n",
    "\n",
    "query = \"Personal organizations are limited to 5000 traces per month\"\n",
    "result = vectorstoredb.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# Initializes an instance of the ChatOpenAI model\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Retrival Chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "'''\n",
    "This class allows you to define structured prompts for chat models. It's designed to handle messages\n",
    "from different roles (system, human, AI)\n",
    "'''\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Answer the following question based on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\"\"\"\n",
    ")\n",
    "'''\n",
    "create_stuff_documents_chain: This is a convenience function in LangChain that creates a chain specifically\n",
    "designed to combine a list of documents into a single string and then \"stuff\" them into the prompt for the\n",
    "LLM. This is a common strategy for providing context to an LLM.\n",
    "Below line, creates the document combining and answering chain.\n",
    "'''\n",
    "document_chain = create_stuff_documents_chain(llm,prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71a0d31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To exceed the limit of 5000 traces per month for personal organizations, you need to add a credit card. This can be done by going to the Plans and Billing page and updating the payment information by adding a credit card.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Giving context to the vectordb and search in that context only\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    # Providing the text to search here\n",
    "    \"input\":\"Personal organizations are limited\",\n",
    "    # Giving the full text where we should focus the search.. implementing RAG \n",
    "    # In a full RAG application, this context list would not be hardcoded. Instead, it would be the result of a similarity search on your vectorstoredb (from the previous steps) based on the user's input. \n",
    "    # For instance, you'd do something like relevant_docs = vectorstoredb.similarity_search(\"Personal organizations are limited\")\n",
    "    # and then pass relevant_docs as the context.\n",
    "    \"context\": [Document(page_content=\"Personal organizations are limited to 5000 traces per month until a credit card is added. You can add a credit card on the Plans and Billing page as follows:\")]\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f52d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding retriever\n",
    "# This line is a crucial step in building a fully functional RAG pipeline because it abstracts\n",
    "#  away the details of the vector search. Instead of manually performing embeddings.embed_query\n",
    "# (\"your question\") and then vectorstoredb.similarity_search(query_embedding), you now have a clean,\n",
    "#  standardized retriever object that does all of that for you with a simple call:\n",
    "retriever = vectorstoredb.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "# Purpose: This line is where the magic of RAG truly comes together. \n",
    "# It creates the complete retrieval-augmented generation chain. \n",
    "# retriever: This is the retriever object we defined earlier (vectorstoredb.as_retriever()). \n",
    "# Its role in this chain is to take the user's question (input) and find the most relevant documents \n",
    "# from your vectorstoredb.\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever,document_chain)\n",
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec8e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the response from the LLM using Retrival Chain\n",
    "#  Previously we invoked the same thing using document chain, now we are doing with retrival chain, \n",
    "# its much simple to write this way\n",
    "\n",
    "response = retrieval_chain.invoke({\"input\":\"Personal organizations are limited\"})\n",
    "response['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
