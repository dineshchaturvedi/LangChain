{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code snippet sets up the foundational components for a Retrieval-Augmented Generation (RAG) application.\n",
    "# This is a very common pattern used to build chatbots that can answer questions about specific, private data \n",
    "# (in this case, documents about pets).\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companion known for its loyalty and friendliness\",\n",
    "        metadata={\"source\":\"mamal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are Independent pets that enjoy on their own\",\n",
    "        metadata={\"source\":\"mamal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Goldfish are popular pets for beginers requiring relatively simply care\",\n",
    "        metadata={\"source\":\"mamal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Parrots are intelligent bird capable of mimiking human speech\",\n",
    "        metadata={\"source\":\"mamal-pets-doc\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Rabbits are social animals that needs plenty of space to hop around\",\n",
    "        metadata={\"source\":\"mamal-pets-doc\"},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5eebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os                          # for operating system work\n",
    "from dotenv import load_dotenv     # to load environment variables \n",
    "from langchain_groq import ChatGroq # for the chat module\n",
    "\n",
    "load_dotenv() # loading all the environment variables\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\") # get the groq api key\n",
    "os.environ[\"HF_TOKEN\"] = os.getenv(\"HF_TOKEN\") # get the hugging face access token\n",
    "\n",
    "llm = ChatGroq(model=\"Llama3-8b-8192\",groq_api_key=groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3effda2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This imports a class that interfaces with Hugging Face models specifically designed for creating embeddings.\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd9cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We are using Chroma DB for Vector Store\n",
    "# This imports the Chroma class from langchain_chroma, which is used to create a vector store from documents and embeddings.\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# This creates a vector store using the documents and embeddings created earlier.\n",
    "# The vector store allows for efficient similarity search and retrieval of documents based on their embeddings.\n",
    "vectorstore = Chroma.from_documents(documents=documents,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fa53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This performs a similarity search in the vector store for documents related to the query \"Dogs\".\n",
    "# It returns documents that are most similar to the query based on their embeddings.\n",
    "vectorstore.similarity_search(\"Dogs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3926be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This performs an asynchronous similarity search in the vector store for documents related to the query \"Dogs\".\n",
    "# It returns documents that are most similar to the query based on their embeddings.\n",
    "await vectorstore.asimilarity_search(\"Dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This performs a similarity search in the vector store for documents related to the query \"Dogs\".\n",
    "# It returns documents that are most similar to the query based on their embeddings.    \n",
    "vectorstore.similarity_search_with_score(\"Dogs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7918a77e",
   "metadata": {},
   "source": [
    "LangChain VectorStore Objects do not subclass Runnable, so it cannot be immediatelly integrated into Langchain Expression Language Chain\n",
    "\n",
    "Langchain Retrievers are runnable, so they implement a standard set of methods (e.g. synchronous and aynchronous invoke and batch operations) and are designed to be incorporated in LCEL chains.\n",
    "\n",
    "We can create a simple version of this ourselves, without subclassing Retriever. If we choose what method we wish to use to retrieve documents, we can create runnable easily. Below we will build one round of similarity_search method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2892ad7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07340d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "# This imports the Document class from langchain_core.documents, which is used to represent documents in LangChain.\n",
    "from langchain_core.documents import Document\n",
    "# This imports the RunnableLambda class from langchain_core.runnables, which allows for creating custom runnables \n",
    "# that can be used in LangChain's expression language.\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "# This line wraps the similarity_search method in a RunnableLambda. The retriever variable is now a Runnable object.\n",
    "#    .bind(k=1): This is a powerful feature of LCEL. The .bind() method \"binds\" a keyword argument to a runnable. \n",
    "#     In this case, you are telling the similarity_search function that k (the number of documents to return)\n",
    "#     should always be 1. This value is now fixed for this specific retriever object.\n",
    "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1)\n",
    "# The .batch() method is designed to process multiple inputs at once, in parallel if possible, and return a list of outputs.\n",
    "# The retriever.batch([\"cat\", \"dog\"]) call will perform two separate retrievals.\n",
    "# This performs a batch retrieval for the queries \"cat\" and \"dog\".\n",
    "retriever.batch([\"cat\",\"dog\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b82b55f",
   "metadata": {},
   "source": [
    "Vectorstore implement an as_retriever method that will generate a Retriever, specially a VectorStore Retriever.\n",
    "These retrievers include a specific search_type and search_kwargs attributes that identify what methods of the underlying vectorstore to call, and how to parametrize them. For example we can replicate the above with the following\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bacc8d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='f3e14f5e-1ef8-40ea-8159-337f0e7b3670', metadata={'source': 'mamal-pets-doc'}, page_content='Cats are Independent pets that enjoy on their own')],\n",
       " [Document(id='4c75d691-5097-4f13-be2e-a0196d5ede00', metadata={'source': 'mamal-pets-doc'}, page_content='Dogs are great companion known for its loyalty and friendliness')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",  # Specifies the type of search to perform\n",
    "    search_kwargs={\"k\": 1}  # Specifies the number of documents to return for each query\n",
    ")\n",
    "retriever.batch([\"cat\",\"dog\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f59d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, Dogs are great companions known for their loyalty and friendliness.\n"
     ]
    }
   ],
   "source": [
    "# Basic RAG example using LangChain Expression Language (LCEL)\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "messages = \"\"\"\n",
    "Answer this question, using the provided context only.\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "# first ( and ): The parentheses for the method call ChatPromptTemplate.from_messages().\n",
    "\n",
    "# second [ and ]: The brackets for the list of messages.\n",
    "\n",
    "# third ( and ): The parentheses for the tuple representing a single message (role, content).\n",
    "# List can take multiple tuples and hence list is used.\n",
    "prompt=ChatPromptTemplate.from_messages ([(\"human\",messages)])\n",
    "# In a LangChain Expression Language (LCEL) chain, everything inside the dictionary has to be a Runnable.\n",
    "# The RunnablePassthrough() is a special runnable that simply passes the input through without any modification.\n",
    "# Its used to pass the \"tell me about Dogs as runnable instead of a string.\"\n",
    "\n",
    "rag_chain = {\"context\":retriever,\"question\":RunnablePassthrough()} | prompt | llm\n",
    "response = rag_chain.invoke(\"tell me about Dogs\")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
